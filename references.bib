@misc{allen2025Cardsim,
	type = {SSRN Scholarly Paper},
	title = {Cardsim: A Bayesian Simulator for Payment Card Fraud Detection Research},
	author = {Allen, Jeffrey},
	year = {2025},
	month = feb,
	number = {5179591},
	eprint = {5179591},
	publisher = {Social Science Research Network},
	address = {Rochester, NY},
	abstract = {Payment fraud has been high in recent years, and as criminals gain access to capability-enhancing generative AI tools, there is a growing need for innovative fraud detection research. However, the pace, diversity, and reproducibility of such research are inhibited by the dearth of publicly available payment transaction data. A few payment simulation methodologies have been developed to help narrow the payment transaction data gap without compromising important data privacy and security expectations. While these simulation approaches have enabled research advancements, more work is needed to generate datasets that reflect diverse and evolving fraud tactics. This paper introduces CardSim, a flexible, scalable payment card transaction simulation methodology that extends the small but emerging body of simulators available for payment fraud modeling research. CardSim is novel in the extent to which it is calibrated to publicly available data and in its Bayesian approach to associating payment transaction features with fraud. The simulator's modular structure, which is operationalized in a corresponding software package, makes it easy to update based on new evidence about payment trends or fraud patterns. After laying out the simulation methodology, I show how outputs can be used to test and evaluate machine learning workflows, modeling approaches, and interpretability frameworks that are relevant for payment card fraud detection.},
	archiveprefix = {Social Science Research Network},
	keywords = {Bayesian analysis,Fraud detection,Machine learning,Payment cards,Simulation},
	file = {/Users/alexwzk/Zotero/storage/8RRDVII2/Allen - 2025 - Cardsim A Bayesian Simulator for Payment Card Fraud Detection Research.pdf}
}

@article{almansouri2026Machine,
	title = {Machine Learning Model for Predicting Cyber-Criminal Characteristics},
	author = {Almansouri, Hesham A. and Khajah, Mohammad M. and Alsnayen, Nasser B.},
	year = {2026},
	month = jan,
	journal = {Kuwait Journal of Science},
	volume = {53},
	number = {1},
	pages = {100487},
	abstract = {This study aims to predict investigation outcomes of individual cybercrime cases using the most relevant information provided by complainants. We curated a dataset on solved hacking cases from 2019 to 2022 from the cyber-crime combating department (3CD) in the State of Kuwait. Each case has a set of information provided by the complainants (input features), and a corresponding set of investigation results (outputs). For each output, several machine learning models, such as decision trees and feed-forward neural networks, were evaluated, via nested 5-fold cross-validation to measure how well they could predict the output, given the input features. Input feature sets were either selected from all possible input feature combinations (brute force) or from a limited set of officer-provided combinations (officer-guided). Finally, a post-hoc analysis of the results was performed to identify a single set of features that can be used to build reasonably predictive models for all collected outputs. Depending on the output, the brute force and officer-guided approaches have a median relative advantage of 92\% and 53\% over the baseline models and worst-officer score respectively. On almost all outputs, the brute-force approach is just as good, if not better, than the officer-guided approach. No relationship was observed between officer rank and the predictive power of the combination of features they selected. Different outputs require different sets of features, and there is a significant overlap between brute force and officer-guided features in five out of the 10 outputs. Most selected features have a reliable negative impact on prediction performance when perturbed, with some outputs relying on a few critical features and others on a spectrum of features. Finally, a single set of features can predict most outputs almost as well as output-specific features.},
	keywords = {AI,Criminology,General Forensics},
	file = {/Users/alexwzk/Zotero/storage/FN2MPTKW/Almansouri et al. - 2026 - Machine learning model for predicting cyber-criminal characteristics.pdf;/Users/alexwzk/Zotero/storage/UXVM5M6W/S2307410825001312.html}
}

@techreport{arthur2024Implications,
	title = {The Implications of AI for Criminal Justice},
	author = {Arthur, Kirk and Bains, Chiraag and Cunningham, Veronica Ballard and Berk, Richard and Buenger, Michael and Casey, Pamela M},
	year = {2024},
	month = oct,
	institution = {Concil on Criminal Justice},
	keywords = {AI,Digital Forensics},
	file = {/Users/alexwzk/Zotero/storage/V44679SG/Arthur et al. - The Implications of AI for Criminal Justice.pdf}
}

@article{bai2025Building,
	title = {Building a Cybersecurity and AI Integrated Learning Pathway for Criminal Justice Professionals},
	author = {Bai, Yan and Li, Juan},
	year = {2025},
	month = apr,
	journal = {Journal of The Colloquium for Information Systems Security Education},
	volume = {12},
	number = {1},
	pages = {7--7},
	abstract = {With support from the National Science Foundation, The University of Washington Tacoma and North Dakota State University have developed scenario-based security curriculum and online showcase labs with interactive simulations and case studies across three progressive courses, revolutionizing cybersecurity education for Criminal Justice (CJ) professionals. By incorporating artificial intelligence into the curriculum, this project enhances CJ professionals' capabilities. Our goal is to develop a skilled workforce of CJ professionals with cybersecurity and privacy knowledge, addressing the critical need for such cybersecurity expertise in CJ. Literature review, focus group survey results, course framework tailored for CJ professionals, example course modules, and implementation results are presented.},
	keywords = {Education,General Forensics},
	file = {/Users/alexwzk/Zotero/storage/FPIB39BF/Bai and Li - 2025 - Building a Cybersecurity and AI Integrated Learning Pathway for Criminal Justice Professionals.pdf}
}

@article{bastian2015Confidence,
	title = {The Confidence Information Ontology: A Step Towards a Standard for Asserting Confidence in Annotations},
	author = {Bastian, Frederic B. and Chibucos, Marcus C. and Gaudet, Pascale and Giglio, Michelle and Holliday, Gemma L. and Huang, Hong and Lewis, Suzanna E. and Niknejad, Anne and Orchard, Sandra and Poux, Sylvain and Skunca, Nives and {Robinson-Rechavi}, Marc},
	year = {2015},
	month = may,
	journal = {Database: The Journal of Biological Databases and Curation},
	volume = {2015},
	pages = {bav043},
	abstract = {Biocuration has become a cornerstone for analyses in biology, and to meet needs, the amount of annotations has considerably grown in recent years. However, the reliability of these annotations varies; it has thus become necessary to be able to assess the confidence in annotations. Although several resources already provide confidence information about the annotations that they produce, a standard way of providing such information has yet to be defined. This lack of standardization undermines the propagation of knowledge across resources, as well as the credibility of results from high-throughput analyses. Seeded at a workshop during the Biocuration 2012 conference, a working group has been created to address this problem. We present here the elements that were identified as essential for assessing confidence in annotations, as well as a draft ontology---the Confidence Information Ontology---to illustrate how the problems identified could be addressed. We hope that this effort will provide a home for discussing this major issue among the biocuration community., Tracker URL: https://github.com/BgeeDB/confidence-information-ontology , Ontology URL: https://raw.githubusercontent.com/BgeeDB/confidence-information-ontology/master/src/ontology/cio-simple.obo},
	keywords = {Digital Forensics,Uncertainty},
	file = {/Users/alexwzk/Zotero/storage/G783RC7K/Bastian et al. - 2015 - The Confidence Information Ontology a step towards a standard for asserting confidence in annotatio.pdf}
}

@inproceedings{bellandi2020Graph,
	title = {Graph Embeddings in Criminal Investigation: Extending the Scope of Enquiry Protocols},
	booktitle = {MEDES},
	author = {Bellandi, Valerio and Ceravolo, Paolo and Maghool, Samira and Siccardi, Stefano},
	year = {2020},
	month = nov,
	pages = {64--71},
	abstract = {Knowledge graphs are exploited in criminal investigation to integrate heterogeneous data sources and scale up the operational efficiency of enquiry protocols. Using a declarative perspective, protocols can be viewed as a set of data ingestion procedures and nested exact queries. This meets the probating nature of procedural justice that has to proceed from established facts. At the same time, the exact specification of queries represents a limit for enquiry protocols that can exclusively retrieve those facts in adherence to the designed queries. We then investigated the use of graph em-beddings procedures to extend the scope of a protocol by returning sub-graphs partially matching to its specification. Because exploring the entire set of sub-graphs quickly become computationally intractable, we developed an approach based on a hierarchical filtering procedure. A controlled experiment we executed has shown the feasibility of our approach.},
	keywords = {Digital Forensics,Knowledge Graphs,Read},
	file = {/Users/alexwzk/Zotero/storage/KHSP5HID/Bellandi et al. - 2020 - Graph Embeddings in Criminal Investigation Extending the Scope of Enquiry Protocols.pdf}
}

@inproceedings{bellandi2022Data,
	title = {Data Fusion and Graph Analysis in Fraud Transaction Detection: Walkthrough of a Case Study},
	booktitle = {Big Data},
	author = {Bellandi, Valerio and Siccardi, Stefano},
	year = {2022},
	month = dec,
	pages = {4601--4605},
	abstract = {The use of data acquisition and fusion techniques allow to generate event graphs in support of criminal investigations. In this paper, an anonymized real case study will be presented to identify undue transactions through graph analysis. All the steps of an investigation protocol are illustrated by describing how the tools adopted in this paper allow to semi-automatically analyze huge amounts of data coming from different nature, identifying suspicious transactions with high precision.},
	keywords = {Digital Forensics,Important,Knowledge Graphs},
	file = {/Users/alexwzk/Zotero/storage/TCSAGPRT/Bellandi and Siccardi - 2022 - Data Fusion and Graph Analysis in Fraud Transaction Detection walkthrough of a case study.pdf}
}

@article{bellandi2022Graph,
	title = {Graph Embeddings in Criminal Investigation: Towards Combining Precision, Generalization and Transparency},
	author = {Bellandi, Valerio and Ceravolo, Paolo and Maghool, Samira and Siccardi, Stefano},
	year = {2022},
	month = nov,
	journal = {World Wide Web},
	volume = {25},
	number = {6},
	pages = {2379--2402},
	abstract = {Criminal investigation adopts Artificial Intelligence to enhance the volume of the facts that can be investigated and documented in trials. However, the abstract reasoning implied in legal justification and argumentation requests to adopt solutions providing high precision, low generalization error, and retrospective transparency. Three requirements that hardly coexist in today's Artificial Intelligence solutions. In a controlled experiment, we then investigated the use of graph embeddings procedures to retrieve potential criminal actions based on patterns defined in enquiry protocols. We observed that a significant level of accuracy can be achieved but different graph reformation procedures imply different levels of precision, generalization, and transparency.},
	keywords = {AI,Digital Forensics,Important,Knowledge Graphs},
	file = {/Users/alexwzk/Zotero/storage/IYWRYWTF/Bellandi et al. - 2022 - Graph embeddings in criminal investigation towards combining precision, generalization and transpar.pdf}
}

@inproceedings{bellandi2023NLPBased,
	title = {An NLP-Based Statistical Reporting Methodology Applied to Court Decisions},
	booktitle = {SEAA},
	author = {Bellandi, Valerio and Maghool, Samira and Siccardi, Stefano},
	year = {2023},
	month = sep,
	pages = {108--111},
	abstract = {Natural Language Processing (NLP) algorithms have significantly advanced the capabilities of understanding, processing and generating human language. However, one persistent challenge in NLP is the problem of uncertainty, due e.g. to the inherent complexity of human language, variations in language usage across different contexts and domains, and the presence of noisy or incomplete data. In this work we take in consideration this problem for statistics derived from court documents by NLP systems.},
	keywords = {AI,Digital Forensics,Knowledge Graphs},
	file = {/Users/alexwzk/Zotero/storage/RT3B67Q5/Bellandi et al. - 2023 - An NLP-based statistical reporting methodology applied to court decisions.pdf}
}

@incollection{bench-capon2024Computational,
	title = {Computational Models of Legal Argument},
	booktitle = {Handbook of Formal Argumentation},
	author = {{Bench-Capon}, Trevor and Atkinson, Katie and Bex, Floris and Prakken, Henry and Verheij, Bart},
	year = {2024},
	volume = {3},
	publisher = {College Publications},
	keywords = {Legal},
	file = {/Users/alexwzk/Zotero/storage/HVBB5BXS/Bench-Capon et al. - Computational Models of Legal Argument.pdf}
}

@inproceedings{bhatt2021Uncertainty,
	title = {Uncertainty as a Form of Transparency: Measuring, Communicating, and Using Uncertainty},
	booktitle = {AIES},
	author = {Bhatt, Umang and Antor{\'a}n, Javier and Zhang, Yunfeng and Liao, Q. Vera and Sattigeri, Prasanna and Fogliato, Riccardo and Melan{\c c}on, Gabrielle and Krishnan, Ranganath and Stanley, Jason and Tickoo, Omesh and Nachman, Lama and Chunara, Rumi and Srikumar, Madhulika and Weller, Adrian and Xiang, Alice},
	year = {2021},
	month = jul,
	pages = {401--413},
	abstract = {Algorithmic transparency entails exposing system properties to various stakeholders for purposes that include understanding, improving, and contesting predictions. Until now, most research into algorithmic transparency has predominantly focused on explainability. Explainability attempts to provide reasons for a machine learning model's behavior to stakeholders. However, understanding a model's specific behavior alone might not be enough for stakeholders to gauge whether the model is wrong or lacks sufficient knowledge to solve the task at hand. In this paper, we argue for considering a complementary form of transparency by estimating and communicating the uncertainty associated with model predictions. First, we discuss methods for assessing uncertainty. Then, we characterize how uncertainty can be used to mitigate model unfairness, augment decision-making, and build trustworthy systems. Finally, we outline methods for displaying uncertainty to stakeholders and recommend how to collect information required for incorporating uncertainty into existing ML pipelines. This work constitutes an interdisciplinary review drawn from literature spanning machine learning, visualization/HCI, design, decision-making, and fairness. We aim to encourage researchers and practitioners to measure, communicate, and use uncertainty as a form of transparency.},
	keywords = {AI,Uncertainty},
	file = {/Users/alexwzk/Zotero/storage/JLYRLT8J/Bhatt et al. - 2021 - Uncertainty as a Form of Transparency Measuring, Communicating, and Using Uncertainty.pdf}
}

@article{bilgin2024Determining,
	title = {Determining Legal Relevance with LLMs using Relevance Chain Prompting},
	author = {Bilgin, Onur and Licato, John},
	year = {2024},
	month = may,
	journal = {FLAIRS},
	volume = {37},
	abstract = {In legal reasoning, part of determining whether evidence should be admissible in court requires assessing its relevance to the case, often formalized as its probative value---the degree to which its being true or false proves a fact in issue. However, determining probative value is an imprecise process and must often rely on consideration of arguments for and against the probative value of a fact. Can generative language models be of use in generating or assessing such arguments? In this work, we introduce relevance chain prompting, a new prompting method that enables large language models to reason about the relevance of evidence to a given fact and uses measures of chain strength. We explore different methods for scoring a relevance chain grounded in the idea of probative value. Additionally, we evaluate the outputs of large language models with ROSCOE metrics and compare the results to chain-of-thought prompting. We test the prompting methods on a dataset created from the Legal Evidence Retrieval dataset. After postprocessing with the ROSCOE metrics, our method outperforms chain-of-thought prompting.},
	keywords = {AI,Decision Making,Legal},
	file = {/Users/alexwzk/Zotero/storage/7UBEVFKD/Bilgin and Licato - 2024 - Determining Legal Relevance with LLMs using Relevance Chain Prompting.pdf}
}

@article{carloni2025Role,
	title = {The Role of Causality in Explainable Artificial Intelligence},
	author = {Carloni, Gianluca and Berti, Andrea and Colantonio, Sara},
	year = {2025},
	month = jun,
	journal = {WIREs Data Min. \& Knowl.},
	volume = {15},
	number = {2},
	pages = {e70015},
	abstract = {Causality and eXplainable Artificial Intelligence (XAI) have developed as separate fields in computer science, even though the underlying concepts of causation and explanation share common ancient roots. This is further enforced by the lack of review works jointly covering these two fields. In this paper, we investigate the literature to try to understand how and to what extent causality and XAI are intertwined. More precisely, we seek to uncover what kinds of relationships exist between the two concepts and how one can benefit from them, for instance, in building trust in AI systems. As a result, three main perspectives are identified. In the first one, the lack of causality is seen as one of the major limitations of current AI and XAI approaches, and the ``optimal'' form of explanations is investigated. The second is a pragmatic perspective and considers XAI as a tool to foster scientific exploration for causal inquiry, via the identification of pursue-worthy experimental manipulations. Finally, the third perspective supports the idea that causality is propaedeutic to XAI in three possible manners: exploiting concepts borrowed from causality to support or improve XAI, utilizing counterfactuals for explainability, and considering accessing a causal model as explaining itself. To complement our analysis, we also provide relevant software solutions used to automate causal tasks. We believe our work provides a unified view of the two fields of causality and XAI by highlighting potential domain bridges and uncovering possible limitations.},
	keywords = {AI,Causal Reasoning},
	file = {/Users/alexwzk/Zotero/storage/TI665L88/Carloni et al. - 2025 - The Role of Causality in Explainable Artificial Intelligence.pdf}
}

@article{carvalho2017PROWL,
	title = {PR-OWL -- A Language for Defining Probabilistic Ontologies},
	author = {Carvalho, Rommel N. and Laskey, Kathryn B. and Costa, Paulo C. G.},
	year = {2017},
	month = dec,
	journal = {International Journal of Approximate Reasoning},
	volume = {91},
	pages = {56--79},
	abstract = {Recent years have witnessed an increasingly mature body of research on the Semantic Web (SW), with new standards being developed and more complex problems being addressed. As complexity increases in SW applications, so does the need to cope with uncertainty. Several approaches to uncertainty representation and reasoning in the SW have emerged. Among these is Probabilistic Web Ontology Language (PR-OWL), which provides a means of representing uncertainty in ontologies expressed in Web Ontology Language (OWL). PR-OWL allows values of random variables to range over OWL datatypes, following an approach suggested by Poole et al. to formalizing the association between random variables from probabilistic theories with the individuals, classes and properties from ontological languages such as OWL.},
	keywords = {Bayesian Network,Causal Reasoning,Uncertainty},
	file = {/Users/alexwzk/Zotero/storage/RCLBJSVE/Carvalho et al. - 2017 - PR-OWL – a language for defining probabilistic ontologies.pdf;/Users/alexwzk/Zotero/storage/ZZ3P574S/S0888613X17301044.html}
}

@misc{catlin2025Game,
	title = {The Game is the Game: Dynamic network analysis and shifting roles in criminal networks},
	author = {Catlin, Daniel and Berlusconi, Giulia and Lloyd, David J. B.},
	year = {2025},
	month = sep,
	number = {arXiv:2509.08028},
	eprint = {2509.08028},
	primaryclass = {cs},
	publisher = {arXiv},
	abstract = {Objectives: This paper incorporates time as a crucial variable to identify key players in criminal networks and explores how actors' positions change over time. It then assesses the accuracy of the results against the uncertainty around network data collected from criminal justice records. Methods: Network data are from a judicial document for a two-year investigation targeting a drug trafficking and distribution network. We use Katz centrality in its dynamic version to explore changes in relationships and relative importance of network actors. We then use a novel method of introducing new edges to the network using Bernoulli random trials to simulate missing data and assess the extent to which node rankings based on Katz centrality change or remain the same when introducing some level of uncertainty to our observed network. Results: We identify actors who consistently held a central role over the course of the two-year investigation and differentiate them from actors who provided key contributions to the group's activities, but only for a limited period. We show that compared to centrality measures commonly used in criminal network analysis, dynamic Katz centrality is helpful to differentiate individual contributions even among central nodes and explore individual trajectories over time, even when data are incomplete. Conclusions: This paper demonstrates the value of key player identification using temporal network data and offers an additional analytical tool to both organised crime scholars trying to capture the complex nature of criminal collaboration and law enforcement agencies aiming at identifying appropriate targets and disrupting criminal groups.},
	archiveprefix = {arXiv},
	keywords = {Computer Science - Social and Information Networks},
	file = {/Users/alexwzk/Zotero/storage/YGQPRM5Z/Catlin et al. - 2025 - The Game is the Game Dynamic network analysis and shifting roles in criminal networks.pdf;/Users/alexwzk/Zotero/storage/6L3BFDVT/2509.html}
}

@article{cebreros2025Facial,
	title = {Facial Recognition Technology and Wrongful Arrests in the Digital Policing Era},
	author = {Cebreros, Jannice},
	year = {2025},
	journal = {Washington Law Review Online},
	volume = {100},
	number = {2},
	pages = {33},
	abstract = {This Essay examines the use of facial recognition technology (FRT) by law enforcement agencies, the implications of such use, and the disproportionate impact the use has on Black, Indigenous, and People of Color (BIPOC) communities. Law enforcement officers are increasingly using FRT for the purpose of identifying suspects. Essentially, law enforcement officers will take a ``still image'' of a suspect, upload this image into a database, and find a potential match, which the officers then use to identify an individual. This Essay argues that legislatures must enact law that limits the use of FRT by law enforcement agencies, especially when the agency fully depends on the technology's identification of a person. This kind of software is biased from its development, particularly in its inability to accurately identify women and BIPOC individuals. Washington State has recently taken the lead by attempting to regulate the use of stingrays and drones and should take the lead once more in further protecting BIPOC communities against the disproportionate and harmful impacts of racially biased and inaccurate FRT. This Essay concludes by proposing legislation for Washington State that would limit the use of FRT by law enforcement agencies.},
	keywords = {Facial Recognition},
	file = {/Users/alexwzk/Zotero/storage/KTJ4NDLN/Cebreros - Facial Recognition Technology and Wrongful Arrests in the Digital Policing Era.pdf}
}

@article{chessman2017Source,
	title = {A 'Source' of Error: Computer Code, Criminal Defendants, and the Constitution},
	author = {Chessman, Christian},
	year = {2017},
	month = feb,
	journal = {California Law Review},
	volume = {105},
	number = {1},
	pages = {179--228},
	abstract = {Evidence created by computer programs dominates modern criminal trials. From DNA to fingerprints to facial recognition evidence, criminal courts are confronting a deluge of evidence that is generated by computer programs. In a worrying trend, a growing number of courts have insulated this evidence from adversarial testing by preventing defendants from accessing the source code that governs the computer programs. This Note argues that defendants are entitled to view, test, and critique the source code of computer programs that produce evidence offered at trial by the prosecution. To do so, this Note draws on three areas of law: the Confrontation Clause, the Due Process Clause, and Daubert and its progeny. While courts and commentators have grappled with specific computer programs in specific criminal contexts, this Note represents the first attempt to justify the systematic disclosure of source code by reference to the structural features of computer programs.},
	keywords = {Criminology,Read},
	file = {/Users/alexwzk/Zotero/storage/7IK92RED/Chessman - 2016 - A 'Source' of Error Computer Code, Criminal Defendants, and the Constitution.pdf}
}

@article{constant2024Bayesian,
	title = {A Bayesian Model of Legal Syllogistic Reasoning},
	author = {Constant, Axel},
	year = {2024},
	month = jun,
	journal = {Artif. Intell. Law},
	volume = {32},
	number = {2},
	pages = {441--462},
	abstract = {Bayesian approaches to legal reasoning propose causal models of the relation between evidence, the credibility of evidence, and ultimate hypotheses, or verdicts. They assume that legal reasoning is the process whereby one infers the posterior probability of a verdict based on observed evidence, or facts. In practice, legal reasoning does not operate quite that way. Legal reasoning is also an attempt at inferring applicable rules derived from legal precedents or statutes based on the facts at hand. To make such an inference, legal reasoning follows syllogistic logic and first order transitivity. This paper proposes a Bayesian model of legal syllogistic reasoning that complements existing Bayesian models of legal reasoning using a Bayesian network whose variables correspond to legal precedents, statutes, and facts. We suggest that legal reasoning should be modelled as a process of finding the posterior probability of precedents and statutes based on available facts.},
	keywords = {Bayesian Network,Decision Making,Legal},
	file = {/Users/alexwzk/Zotero/storage/ETNRXBIJ/Constant - 2024 - A Bayesian model of legal syllogistic reasoning.pdf}
}

@article{cramer2025How,
	title = {How the N.Y.P.D.'s Facial Recognition Tool Landed the Wrong Man in Jail},
	author = {Cramer, Maria and Hill, Kashmir},
	year = {2025},
	month = aug,
	journal = {The New York Times},
	urldate = {2025-09-08},
	abstract = {Trevis Williams is eight inches taller than a man accused of flashing a woman in Union Square in February. The police arrested him anyway.},
	keywords = {American Civil Liberties Union,Brooklyn (NYC),Department of Investigation (NYC),Facial Recognition Software,False Arrests Convictions and Imprisonments,National Institute of Standards and Technology,Police,Police Department (NYC)},
	file = {/Users/alexwzk/Zotero/storage/KL9AJYK3/nypd-facial-recognition-dismissed-case.html}
}

@article{dahlman2022Causal,
	title = {Causal Models Versus Reason Models in Bayesian Networks for Legal Evidence},
	author = {Dahlman, Christian and Kolflaath, Eivind},
	year = {2022},
	month = nov,
	journal = {Synthese},
	volume = {200},
	number = {6},
	pages = {477},
	abstract = {In this paper we compare causal models with reason models in the construction of Bayesian networks for legal evidence. In causal models, arrows in the network are drawn from causes to effects. In a reason model, the arrows are instead drawn towards the evidence, from factum probandum to factum probans. We explore the differences between causal models and reason models and observe several distinct advantages with reason models. Reason models are better aligned with the philosophy of Bayesian inference, as they model reasons for up-dating beliefs. Reason models are better suited for measuring the combined support of the evidence, and a prior probability of guilt that reflects the number of possible perpetrators is accommodated more easily with reason models.},
	keywords = {Bayesian Network,Causal Reasoning,Legal},
	file = {/Users/alexwzk/Zotero/storage/ZXNSPMCZ/Dahlman and Kolflaath - 2022 - Causal models versus reason models in Bayesian networks for legal evidence.pdf}
}

@inproceedings{denies2013Modeling,
	title = {Modeling Uncertain Provenance and Provenance of Uncertainty in W3C PROV},
	booktitle = {WWW Companion},
	author = {De Nies, Tom and Coppens, Sam and Mannens, Erik and {Van de Walle}, Rik},
	year = {2013},
	month = may,
	pages = {167--168},
	abstract = {This paper describes how to model uncertain provenance and provenance of uncertain things in a flexible and unintrusive manner using PROV, W3C's new standard for provenance. Three new attributes with clearly defined values and semantics are proposed. Modeling this information is an important step towards the modeling and derivation of trust from resources whose provenance is described using PROV.},
	keywords = {General Forensics,Uncertainty},
	file = {/Users/alexwzk/Zotero/storage/46MDNNF2/De Nies et al. - 2013 - Modeling uncertain provenance and provenance of uncertainty in W3C PROV.pdf}
}

@article{elaad2022Tunnel,
	title = {Tunnel Vision and Confirmation Bias Among Police Investigators and Laypeople in Hypothetical Criminal Contexts},
	author = {Elaad, Eitan},
	year = {2022},
	month = apr,
	journal = {SAGE Open},
	volume = {12},
	number = {2},
	pages = {21582440221095022},
	abstract = {Tunnel vision is the tendency of actors in the criminal justice system to use short-cuts to filter evidence selectively to build a case for a suspect's conviction. Confirmation bias tends to favor information that confirms an individual's preconceptions independently of the information's accuracy: the present study manipulated tunnel vision and confirmation bias. The purpose was to examine the combined effects of these biases on Israeli police investigators and laypeople in hypothetical criminal investigation situations. Results indicated that police investigators were more strongly affected than laypersons by tunnel vision. Police investigators were more confident about the suspect's guilt than were laypeople in the presence of incriminating and exonerating information, alike. Still, investigators did not ignore exonerating information and lowered their confidence in the suspect's guilt when exonerating information was presented. We discussed the results according to police legitimacy and self-assessed lie-detection ability, which is rated higher by police investigators than by laypeople.},
	keywords = {Legal,Responsible},
	file = {/Users/alexwzk/Zotero/storage/E8GWHX8U/Elaad - 2022 - Tunnel Vision and Confirmation Bias Among Police Investigators and Laypeople in Hypothetical Crimina.pdf}
}

@article{fahsing2023Have,
	title = {Have You Considered the Opposite? A Debiasing Strategy for Judgment in Criminal Investigation},
	author = {Fahsing, Ivar and Rachlew, Asbj{\o}rn and May, Lennart},
	year = {2023},
	month = mar,
	journal = {Police Journal},
	volume = {96},
	number = {1},
	pages = {45--60},
	abstract = {Fundamental challenges in human decision-making pose a serious threat to fair evidence evaluation, verdicts in court proceedings, and the administration of justice. Drawing on cognitive psychology, we examined whether a consider-the-opposite approach can assist police officers with positive guidance on how to implement crucial legal thresholds such as the presumption of innocence. In an experiment with sworn police officers (N = 100), we compared a consider-the-opposite condition and a control condition (with no further instructions) and measured the formulated alternative hypotheses. The results show a promising debiasing effect of the consider-the-opposite approach which may strengthen fundamental principles of criminal law.},
	keywords = {Decision Making,Legal,Responsible},
	file = {/Users/alexwzk/Zotero/storage/43UJ9TXA/Fahsing et al. - 2023 - Have you considered the opposite A debiasing strategy for judgment in criminal investigation..pdf}
}

@article{faqir2023Digital,
	title = {Digital Criminal Investigations in the Era of Artificial Intelligence: A Comprehensive Overview},
	author = {Faqir, Raed S. A.},
	year = {2023},
	month = nov,
	journal = {International Journal of Cyber Criminology},
	volume = {17},
	number = {2},
	pages = {77--94},
	abstract = {Artificial Intelligence (AI) has been integrated within digital criminal investigations comprehensively with the help of associated methodologies, legal ramifications, and its overarching impact on the justice system. This study adopted a multifaceted approach encompassing qualitative, descriptive, and analytical methods, drawing its data primarily from an array of legal documents and scholarly literature. Through its investigation, this study elucidated the pivotal role that AI plays within law enforcement, encompassing aspects such as arrest procedures, release decisions, sentencing processes, prediction of recidivism, identification of criminal activities and patterns, as well as the apprehension of suspects through advanced audio analysis techniques. The findings underscore the transformative potential of machine learning techniques in enhancing the analysis and organization of case data. The study provides a series of recommendations aimed at optimizing the utilization of AI in digital criminal investigations. These recommendations advocate for the prioritization of high-risk cases through the incorporation of diverse data sources to facilitate well-informed decision-making. Additionally, the study advocates for the deployment of AI in crime prediction, suspect identification, and the reinforcement of security measures. Furthermore, it underscores the importance of implementing AI-powered biometric identification (Bio-ID) systems to fortify identity verification processes. Lastly, the study advocates for the implementation of intelligent surveillance solutions to proactively prevent criminal activities, utilizing advanced visual analysis techniques. Concurrently, it emphasizes the role of machine learning in streamlining case management processes, thereby providing precise recommendations and enhancing overall efficiency within the criminal justice system.},
	keywords = {AI,Digital Forensics,Legal},
	file = {/Users/alexwzk/Zotero/storage/4BZIQPQZ/Faqir - 2023 - Digital Criminal Investigations in the Era of Artificial Intelligence A Comprehensive Overview.pdf}
}

@article{farber2025AI,
	title = {AI as a Decision Support Tool in Forensic Image Analysis: A Pilot Study on Integrating Large Language Models Into Crime Scene Investigation Workflows},
	author = {Farber, Shai},
	year = {2025},
	month = may,
	journal = {J. Forensic Sci.},
	volume = {70},
	number = {3},
	pages = {932--943},
	abstract = {This study evaluates the effectiveness of artificial intelligence (AI) tools (ChatGPT-4, Claude, and Gemini) in forensic image analysis of crime scenes, marking a significant step toward developing bespoke AI models for forensic applications. The research involved independent analysis of 30 crime scene images by the AI tools, with the resulting reports rigorously assessed by 10 forensic experts. Findings reveal promising potential for AI as a decision support tool in forensic science, serving as a rapid initial screening mechanism to assist human experts in their comprehensive analysis. The results emphasize that current AI tools function optimally as assistive technologies, enhancing rather than replacing expert forensic analysis, particularly in scenarios involving multiple evidence points or high-volume caseloads. The AI tools demonstrated high accuracy in observations but faced challenges in evidence identification, with performance varying across different crime scene types---excelling in homicide scenarios (average score of 7.8) but encountering difficulties in arson scenes (average score of 7.1). This study's findings could significantly impact investigative procedures, forensic training, and the development of AI tools in law enforcement, while emphasizing the importance of establishing robust ethical guidelines for the integration of AI in criminal justice systems.},
	keywords = {AI,Important,Responsible,Uncertainty},
	file = {/Users/alexwzk/Zotero/storage/ZPIWZMQX/Farber - 2025 - AI as a decision support tool in forensic image analysis A pilot study on integrating large languag.pdf}
}

@article{fernandez-basso2025AI,
	title = {An AI Knowledge-Based System for Police Assistance in Crime Investigation},
	author = {Fernandez-Basso, Carlos and Guti{\'e}rrez-Batista, Karel and G{\'o}mez-Romero, Juan and Ruiz, M. Dolores and Martin-Bautista, Maria J.},
	year = {2025},
	month = jan,
	journal = {Expert Systems},
	volume = {42},
	number = {1},
	pages = {e13524},
	abstract = {The fight against crime is often an arduous task overall when huge amounts of data have to be inspected, as is currently the case when it comes for example in the detection of criminal activity on the dark web. This work presents and describes an artificial intelligence (AI) based system that combines various tools to assist police or law enforcement agencies during their investigations, or at least mitigate the hard process of data collection, processing and analysis. The system is an early warning/early action system for crime investigation that supports law enforcement with different processes to collect and process data as well as having knowledge extraction tools. It helps to extract information during the investigation of a criminal case or even to detect possible criminal hotspots that may lead to further investigation or analysis of a criminal case Abu Al-Haija et al. (2022, Electronics, 11, 556). The functionality of the proposed system is illustrated through several examples using data collected from the dark web, which includes advertisements offering firearms-related products.},
	keywords = {AI,Digital Forensics,Knowledge Graphs,Read},
	file = {/Users/alexwzk/Zotero/storage/EN5632K3/Fernandez‐Basso et al. - 2025 - An AI knowledge‐based system for police assistance in.pdf}
}

@inproceedings{ficara2021Multilayer,
	title = {Multilayer Network Analysis: The Identification of Key Actors in a Sicilian Mafia Operation},
	booktitle = {Future Access Enablers for Ubiquitous and Intelligent Infrastructures},
	author = {Ficara, Annamaria and Fiumara, Giacomo and De Meo, Pasquale and Catanese, Salvatore},
	editor = {Perakovic, Dragan and Knapcikova, Lucia},
	year = {2021},
	pages = {120--134},
	publisher = {Springer International Publishing},
	abstract = {Recently, Social Network Analysis studies have led to an improvement and to a generalization of existing tools to networks with multiple subsystems and layers of connectivity. These kind of networks are usually called multilayer networks. Multilayer networks in which each layer shares at least one node with some other layer in the network are called multiplex networks. Being a multiplex network does not require all nodes to exist on every layer. In this paper, we built a criminal multiplex network which concerns an anti-mafia operation called ``Montagna'' and it is based on the examination of a pre-trial detention order issued on March 14, 2007 by the judge for preliminary investigations of the Court of Messina (Sicily). ``Montagna'' focus on two Mafia families called ``Mistretta'' and ``Batanesi'' who infiltrated several economic activities including the public works in the north-eastern part of Sicily, through a cartel of entrepreneurs close to the Sicilian Mafia. Originally we derived two single-layer networks, the former capturing meetings between suspected individuals and the latter recording phone calls. But some networked systems can be better modeled by multilayer structures where the individual nodes develop relationships in multiple layers. For this reason we built a two-layer network from the single-layer ones. These two layers share 47 nodes. We followed three different approaches to measure the importance of nodes in multilayer networks using degree as descriptor. Our analysis can aid in the identification of key players in criminal networks.},
	keywords = {Criminal networks,Multilayer networks,Social network analysis},
	file = {/Users/alexwzk/Zotero/storage/HXWC3KSN/Ficara et al. - 2021 - Multilayer Network Analysis The Identification of Key Actors in a Sicilian Mafia Operation.pdf}
}

@article{fischer-abaigar2024Bridging,
	title = {Bridging the gap: Towards an expanded toolkit for AI-driven decision-making in the public sector},
	author = {{Fischer-Abaigar}, Unai and Kern, Christoph and Barda, Noam and Kreuter, Frauke},
	year = {2024},
	month = dec,
	journal = {Government Information Quarterly},
	volume = {41},
	number = {4},
	pages = {101976},
	abstract = {AI-driven decision-making systems are becoming instrumental in the public sector, with applications spanning areas like criminal justice, social welfare, financial fraud detection, and public health. While these systems offer great potential benefits to institutional decision-making processes, such as improved efficiency and reliability, these systems face the challenge of aligning machine learning (ML) models with the complex realities of public sector decision-making. In this paper, we examine five key challenges where misalignment can occur, including distribution shifts, label bias, the influence of past decision-making on the data side, as well as competing objectives and human-in-the-loop on the model output side. Our findings suggest that standard ML methods often rely on assumptions that do not fully account for these complexities, potentially leading to unreliable and harmful predictions. To address this, we propose a shift in modeling efforts from focusing solely on predictive accuracy to improving decision-making outcomes. We offer guidance for selecting appropriate modeling frameworks, including counterfactual prediction and policy learning, by considering how the model estimand connects to the decision-maker's utility. Additionally, we outline technical methods that address specific challenges within each modeling approach. Finally, we argue for the importance of external input from domain experts and stakeholders to ensure that model assumptions and design choices align with real-world policy objectives, taking a step towards harmonizing AI and public sector objectives.},
	keywords = {AI,Causal Reasoning,Decision Making},
	file = {/Users/alexwzk/Zotero/storage/HWIZPGMJ/Fischer-Abaigar et al. - 2024 - Bridging the gap Towards an expanded toolkit for AI-driven decision-making in the public sector.pdf;/Users/alexwzk/Zotero/storage/Y3ZCBG34/S0740624X24000686.html}
}

@inproceedings{franklin2022Causal,
	title = {Causal Framework of Artificial Autonomous Agent Responsibility},
	booktitle = {AIES},
	author = {Franklin, Matija and Ashton, Hal and Awad, Edmond and Lagnado, David},
	year = {2022},
	month = jul,
	pages = {276--284},
	abstract = {Recent empirical work on people's attributions of responsibility toward artificial autonomous agents (such as Artificial Intelligence agents or robots) has delivered mixed findings. The conflicting results reflect differences in context, the roles of AI and human agents, and the domain of application. In this article, we outline a causal framework of responsibility attribution which integrates these findings. It outlines nine factors that influence responsibility attribution - causality, role, knowledge, objective foreseeability, capability, intent, desire, autonomy, and character. We propose a framework of responsibility that outlines the causal relationships between the nine factors and responsibility. To empirically test the framework we discuss some initial findings and outline an approach to using serious games for causal cognitive research on responsibility attribution. Specifically, we propose a game that uses a generative approach to creating different scenarios, in which participants can freely inspect different sources of information to make judgments about human and artificial autonomous agents.},
	keywords = {AI,Decision Making},
	file = {/Users/alexwzk/Zotero/storage/IR3RA7XH/Franklin et al. - 2022 - Causal Framework of Artificial Autonomous Agent Responsibility.pdf}
}

@article{garrett2020Wrongful,
	title = {Wrongful Convictions},
	author = {Garrett, Brandon L.},
	year = {2020},
	month = jan,
	journal = {Annu. Rev. Criminol.},
	volume = {3},
	number = {1},
	pages = {245--259},
	abstract = {In response to wrongful convictions, there has been a revolution in criminal procedure and research in law and science. This review seeks to summarize the cross-disciplinary explosion in work studying known wrongful convictions, examining their causes, and assessing policy reforms designed to help detect and prevent errors in criminal justice. Scholars have increasingly studied the characteristics of known wrongful-conviction cases, including by analyzing archival records and by creating public registries of exonerations. Scholars have conducted research in law, psychology, statistics, criminology, and other disciplines, as well as interdisciplinary research, designed to better understand the phenomenon of wrongful convictions and how to prevent errors. Scientific bodies, such as the National Academy of Sciences, have made important recommendations based on this research. Furthermore, the conversation is global, with litigation, research, and policy work across jurisdictions. A wide range of jurisdictions have adopted noteworthy changes designed to safeguard crucial types of evidence, such as confession, forensic, and eyewitness evidence, during police investigations and at trial. As a result, law and science have increasingly come together to produce tangible improvements to criminal justice.},
	keywords = {Criminology,Read},
	file = {/Users/alexwzk/Zotero/storage/L4S5KRQK/Garrett - 2020 - Wrongful Convictions.pdf}
}

@article{gless2020AI,
	title = {AI in the Courtroom: A Comparative Analysis of Machine Evidence in Criminal Trials},
	author = {Gless, Sabine},
	year = {2020},
	month = may,
	journal = {Geo. J. Int'l L.},
	volume = {51},
	pages = {195},
	abstract = {As artificial intelligence (AI) has become more commonplace, the monitoring of human behavior by machines and software bots has created so-called machine evidence. This new type of evidence poses procedural challenges in criminal justice systems across the world due to the fact that they have traditionally been tailored for human testimony. This article's focus is on information proffered as evidence in criminal trials which has been generated by AI-driven systems that observe and evaluate the behavior of human users to predict future behavior in an attempt to enhance safety. A poignant example of this type of evidence stemming from data generated by a consumer product is automated driving, where driving assistants as safety features, observe and evaluate a driver's ability to retake control of a vehicle where necessary. In Europe, for instance, new intelligent devices, including drowsiness detection and distraction warning systems, will become mandatory in new cars beginning in 2022. In the event that human-machine interactions cause harm (e.g., an accident involving an automated vehicle), there is likely to be a plethora of machine evidence, or data generated by AI-driven systems, potentially available for use in a criminal trial.It is not yet clear if and how this the data can be used as evidence in criminal fact-finding, and adversarial and inquisitorial systems approach this issue very differently. Adversarial proceedings have the advantage of partisan vetting, which gives both sides the opportunity to challenge consumer products offered as witnesses. By contrast, inquisitorial systems have specific mechanisms in place to introduce expert evidence recorded out-side the courtroom, including to establish facts, which will be necessary to thoroughly test AI.Using the German and the U.S. federal systems as examples, this Article highlights the challenges posed by machine evidence in criminal proceedings. The primary area of comparison is the maintenance of trust in fact-finding as the law evolves to accommodate the use of machine evidence. This comparative perspective illustrates the enigma of AI in the courtroom and foreshadows what will become inevitable problems in the not-too-distant future. The Article con-cludes that, at present, criminal justice systems are not sufficiently equipped to deal with the novel and varied types of information generated by embedded AI in consumer products. It is suggested that we merge the adversarial system's tools for bipartisan vetting of evidence with the inquisitorial system's inclusion of out-of-court statements under specific conditions to establish adequate means of testing machine evidence.},
	keywords = {AI,Digital Forensics,Legal},
	file = {/Users/alexwzk/Zotero/storage/METCH7F2/Gless - 2020 - AI in the Courtroom A Comparative Analysis of Machine Evidence in Criminal Trials.pdf}
}

@article{haley2025Using,
	title = {Using Artificial Intelligence in Law Enforcement and Policing to Improve Public Health and Safety},
	author = {Haley, Patricia and Burrell, Darrell Norman},
	year = {2025},
	month = feb,
	journal = {Law, Economics and Society},
	volume = {1},
	number = {1},
	pages = {p46},
	abstract = {The integration of artificial intelligence (AI) policing tools and geo-profiling into contemporary law enforcement strategies has revolutionized analysis of concerning behavior, offering unprecedented precision in the identification of psychological risk factors and predictive crime analysis. AI's sophisticated pattern recognition capabilities, powered by machine learning algorithms, enable the dissection of vast datasets to uncover complex behavioral trends, latent correlations, and risk indicators often imperceptible to human cognition. This analytical depth enhances law enforcement's ability to identify links between disparate criminal activities, forecast potential threats, and shift from reactive to proactive crime prevention. Complementing AI's prowess, geo-profiling employs spatial analysis rooted in criminology, psychology, and geographic information systems (GIS) to elucidate crime patterns, identify hotspots, and predict offender anchor points. The synergy between these technologies augments investigative efficiency and mitigates cognitive biases inherent in traditional profiling through data-driven objectivity. Moreover, the implications of AI and geo-profiling extend beyond criminal justice, significantly impacting public health and safety. By enhancing crime detection and enabling early intervention, these technologies contribute to reducing violence-related injuries, mitigating psychological trauma, and fostering resilient communities. Police organizations can leverage AI-driven insights to deploy targeted interventions addressing the root causes of violence, such as socio-economic disparities and mental health challenges. This conceptual study explores the transformative potential of AI and geo-profiling in crime prevention, emphasizing their role in advancing public safety, promoting health equity, and informing data-driven policies. Ultimately, these innovations represent a paradigm shift in law enforcement and public health, fostering integrated approaches to address the multifaceted challenges of modern crime and its societal impacts.},
	keywords = {AI,Criminology},
	file = {/Users/alexwzk/Zotero/storage/JJUHG9VJ/Haley and Burrell - 2025 - Using Artificial Intelligence in Law Enforcement and Policing to Improve Public Health and Safety.pdf}
}

@inproceedings{islam2018Uncertainty,
	title = {Uncertainty of Visualizations for SenseMaking in Criminal Intelligence Analysis},
	booktitle = {EuroRV3},
	author = {Islam, M. Junayed and Xu, Kai and Wong, B. L. W.},
	year = {2018},
	pages = {25--29},
	abstract = {Uncertainty in visualization is an inevitable issue for sensemaking in criminal intelligence. Accuracy and precision of adopted visualization techniques have got greater role in trustworthiness with the system while finding out insights from crime related dataset. In this paper, we have presented a case study to introduce concepts of uncertainty and provenance and their relevance to crime analysis. Our findings show how uncertainties of visualization pipeline influence cognitive biases, human awareness and trust-building during crime analysis and how provenance can enhance analysis processes that include uncertainties.},
	keywords = {General Forensics,Uncertainty},
	file = {/Users/alexwzk/Zotero/storage/4S6RBAAW/Islam et al. - 2018 - Uncertainty of Visualizations for SenseMaking in Criminal Intelligence Analysis.pdf}
}

@article{jarnac2025Uncertainty,
	title = {Uncertainty Management in the Construction of Knowledge Graphs: A Survey},
	author = {Jarnac, Lucas and Chabot, Yoan and Couceiro, Miguel},
	editor = {Hogan, Aidan and Hotho, Andreas and Kagal, Lalana and Sattler, Uli},
	year = {2025},
	journal = {TGDK},
	volume = {3},
	number = {1},
	pages = {3:1-3:48},
	abstract = {Knowledge Graphs (KGs) are a major asset for companies thanks to their great flexibility in data representation and their numerous applications, e.g., vocabulary sharing, Q\&A or recommendation systems. To build a KG, it is a common practice to rely on automatic methods for extracting knowledge from various heterogeneous sources. However, in a noisy and uncertain world, knowledge may not be reliable and conflicts between data sources may occur. Integrating unreliable data would directly impact the use of the KG, therefore such conflicts must be resolved. This could be done manually by selecting the best data to integrate. This first approach is highly accurate, but costly and time-consuming. That is why recent efforts focus on automatic approaches, which represent a challenging task since it requires handling the uncertainty of extracted knowledge throughout its integration into the KG. We survey state-of-the-art approaches in this direction and present constructions of both open and enterprise KGs. We then describe different knowledge extraction methods and discuss downstream tasks after knowledge acquisition, including KG completion using embedding models, knowledge alignment, and knowledge fusion in order to address the problem of knowledge uncertainty in KG construction. We conclude with a discussion on the remaining challenges and perspectives when constructing a KG taking into account uncertainty.},
	keywords = {Knowledge Graphs,Uncertainty},
	file = {/Users/alexwzk/Zotero/storage/RXDME5W3/Jarnac et al. - 2025 - Uncertainty Management in the Construction of Knowledge Graphs A Survey.pdf}
}

@article{kassin2013Forensic,
	title = {The Forensic Confirmation Bias: Problems, Perspectives, and Proposed Solutions},
	author = {Kassin, Saul M. and Dror, Itiel E. and Kukucka, Jeff},
	year = {2013},
	month = mar,
	journal = {Journal of Applied Research in Memory and Cognition},
	volume = {2},
	number = {1},
	pages = {42--52},
	abstract = {As illustrated by the mistaken, high-profile fingerprint identification of Brandon Mayfield in the Madrid Bomber case, and consistent with a recent critique by the National Academy of Sciences (2009), it is clear that the forensic sciences are subject to contextual bias and fraught with error. In this article, we describe classic psychological research on primacy, expectancy effects, and observer effects, all of which indicate that context can taint people's perceptions, judgments, and behaviors. Then we describe recent studies indicating that confessions and other types of information can set into motion forensic confirmation biases that corrupt lay witness perceptions and memories as well as the judgments of experts in various domains of forensic science. Finally, we propose best practices that would reduce bias in the forensic laboratory as well as its influence in the courts.},
	keywords = {Causal Reasoning,Criminology},
	file = {/Users/alexwzk/Zotero/storage/WDPF5NVP/Kassin et al. - 2013 - The forensic confirmation bias Problems, perspectives, and proposed solutions..pdf}
}

@article{khodabandehlou2024FiFrauD,
	title = {FiFrauD: Unsupervised Financial Fraud Detection in Dynamic Graph Streams},
	author = {Khodabandehlou, Samira and Golpayegani, Alireza Hashemi},
	year = {2024},
	month = feb,
	journal = {ACM Trans. Knowl. Discov. Data},
	volume = {18},
	number = {5},
	pages = {111:1--111:29},
	abstract = {Given a stream of financial transactions between traders in an e-market, how can we accurately detect fraudulent traders and suspicious behaviors in real time? Despite the efforts made in detecting these fraudsters, this field still faces serious challenges, including the ineffectiveness of existing methods for the complex and streaming environment of e-markets. As a result, it is still difficult to quickly and accurately detect suspected traders and behavior patterns in real-time transactions, and it is still considered an open problem. To solve this problem and alleviate the existing challenges, in this article, we propose FiFrauD, which is an unsupervised, scalable approach that depicts the behavior of manipulators in a transaction stream. In this approach, real-time transactions between traders are converted into a stream of graphs and, instead of using supervised and semi-supervised learning methods, fraudulent traders are detected precisely by exploiting density signals in graphs. Specifically, we reveal the traits of fraudulent traders in the market and propose a novel metric from this perspective, i.e., graph topology, time, and behavior. Then, we search for suspicious blocks by greedily optimizing the proposed metric. Theoretical analysis demonstrates upper bounds for FiFrauD's effectiveness in catching suspicious trades. Extensive experiments on five real-world datasets with both actual and synthetic labels demonstrate that FiFrauD achieves significant accuracy improvements compared with state-of-the-art fraud detection methods. Also, it can find various suspicious behavior patterns in a linear runtime and provide interpretable results. Furthermore, FiFrauD is resistant to the camouflage tactics used by fraudulent traders.},
	file = {/Users/alexwzk/Zotero/storage/5AU7TAPG/Khodabandehlou and Golpayegani - 2024 - FiFrauD Unsupervised Financial Fraud Detection in Dynamic Graph Streams.pdf}
}

@article{kobis2021Bad,
	title = {Bad Machines Corrupt Good Morals},
	author = {K{\"o}bis, Nils and Bonnefon, Jean-Fran{\c c}ois and Rahwan, Iyad},
	year = {2021},
	month = jun,
	journal = {Nat. Hum. Behav.},
	volume = {5},
	number = {6},
	pages = {679--685},
	abstract = {As machines powered by artificial intelligence (AI) influence humans' behaviour in ways that are both like and unlike the ways humans influence each other, worry emerges about the corrupting power of AI agents. To estimate the empirical validity of these fears, we review the available evidence from behavioural science, human--computer interaction and AI research. We propose four main social roles through which both humans and machines can influence ethical behaviour. These are: role model, advisor, partner and delegate. When AI agents become influencers (role models or advisors), their corrupting power may not exceed the corrupting power of humans (yet). However, AI agents acting as enablers of unethical behaviour (partners or delegates) have many characteristics that may let people reap unethical benefits while feeling good about themselves, a potentially perilous interaction. On the basis of these insights, we outline a research agenda to gain behavioural insights for better AI oversight.},
	keywords = {AI},
	file = {/Users/alexwzk/Zotero/storage/MR3WUFDI/Köbis et al. - 2021 - Bad machines corrupt good morals.pdf}
}

@article{kristofik2025Bias,
	title = {Bias in AI (Supported) Decision Making: Old Problems, New Technologies},
	author = {Kri{\v s}tof{\'i}k, Andrej},
	year = {2025},
	month = apr,
	journal = {International Journal for Court Administration},
	volume = {16},
	number = {1},
	abstract = {Recently different regulations and recommendations for the use of AI-based technology, especially in the judiciary, have become more prevalent. One major concern is addressing bias in such systems. In 2016, ProPublica published a damning report on the use of AI-based technology in making decisions about people\&rsquo;s rights and obligations, revealing that such systems tend to replicate and amplify existing biases. The problem arises from the extensive need for training data in machine learning, which is often based on previous data, such as court decisions. For example, the bail system in the US was found to be alarmingly biased against African Americans. Even efforts to avoid mentioning protected characteristics have been shown to be insufficient, as so-called \&ldquo;fairness through unawareness\&rdquo; has been undermined by proxy characteristics. Addressing the bias of AI systems is a crucial issue for the increased involvement of automated means in judicial settings. The following paper examines various biases that might be introduced in AI-based systems, potential solutions and regulations, and compare possible solutions with current approaches of the European Court of Human Rights (ECtHR) towards biases in human judges. The aim is to confront the question of how to approach current bias in judges compared to approaching bias in future AI-based judicial decision-making technology.},
	file = {/Users/alexwzk/Zotero/storage/2RCUYGQX/Krištofík - 2025 - Bias in AI (Supported) Decision Making Old Problems, New Technologies.pdf}
}

@article{ladegaard2020Open,
	title = {Open Secrecy: How Police Crackdowns and Creative Problem-Solving Brought Illegal Markets out of the Shadows},
	author = {Ladegaard, Isak},
	year = {2020},
	month = nov,
	journal = {Soc. Forces},
	volume = {99},
	number = {2},
	pages = {532--559},
	abstract = {Can organized illegal activities grow stronger and more advanced in response to legal pressure? In October 2013, the FBI shut down Silk Road, a thriving e-commerce market for illegal drugs. After the shock, market actors adopted a new identity verification method that enabled mass-migration to other markets, and created websites for information distribution that reduced post-shock uncertainties. The outcome was a decentralized market in which actors could operate in ``open secrecy'' across multiple websites. With verifiable pseudonyms and securely obfuscated real-world identities, actors could publicly discuss, plan, and participate in illegal activities. Threats from police and opportunistic criminals persisted but were no longer crippling concerns as buyers and sellers could reasonably expect that their exchange partners would be available for future business; the illegal market could operate more like a legal one. Drawing on quantitative and qualitative data, the author argues that advances in information technology have expanded the opportunity structure for cooperation and creative problem-solving in the underworld, and therefore that shocks did not hinder but rather stimulate development in digital drug markets. Data, collected in 2013--2017, include nearly one million transactions from three illicit e-commerce markets, three million messages from eight discussion forums, and website traffic from two market-independent websites.},
	keywords = {Criminology,Cybercrime,Dataset},
	file = {/Users/alexwzk/Zotero/storage/KZ8P6NDZ/Ladegaard - 2020 - Open Secrecy How Police Crackdowns and Creative Problem-Solving Brought Illegal Markets out of the.pdf;/Users/alexwzk/Zotero/storage/AIDFCQAC/soz140.html}
}

@incollection{lagnado2017Causation,
	title = {Causation in Legal and Moral Reasoning},
	booktitle = {Oxford Handbook of Causal Reasoning},
	author = {Lagnado, David A. and Gerstenberg, Tobias},
	editor = {Waldmann, Michael R.},
	year = {2017},
	month = may,
	pages = {565--602},
	publisher = {Oxford University Press},
	abstract = {Causation looms large in legal and moral reasoning. People construct causal models of the social and physical world to understand what has happened, how and why, and to allocate responsibility and blame. This chapter explores people's common-sense notion of causation, and shows how it underpins moral and legal judgments. As a guiding framework it uses the causal model framework (Pearl, 2000) rooted in structural models and counterfactuals, and shows how it can resolve many of the problems that beset standard but-for analyses. It argues that legal concepts of causation are closely related to everyday causal reasoning, and both are tailored to the practical concerns of responsibility attribution. Causal models are also critical when people evaluate evidence, both in terms of the stories they tell to make sense of evidence, and the methods they use to assess its credibility and reliability.},
	keywords = {Causal Reasoning,Important,Legal},
	file = {/Users/alexwzk/Zotero/storage/EMR6MRDS/Lagnado and Gerstenberg - 2017 - Causation in Legal and Moral Reasoning.pdf}
}

@book{lagnado2022Explaining,
	title = {Explaining the Evidence: How the Mind Investigates the World},
	author = {Lagnado, David A.},
	year = {2022},
	publisher = {Cambridge University Press},
	abstract = {"How do we make sense of complex evidence? What are the cognitive principles that allow detectives to solve crimes and lay people to puzzle out everyday problems? To address these questions, David Lagnado presents a novel perspective on human reasoning. At heart, we are causal thinkers driven to explain the myriad ways in which people behave and interact. We build mental models of the world, enabling us to infer patterns of cause and effect, linking words to deeds, actions to effects, and crimes to evidence. But building models is not enough; we need to evaluate these models against evidence, and we often struggle with this task. We have a knack for explaining, but less skill at evaluating. Fortunately, we can improve our reasoning by reflecting on inferential practices and using formal tools. This book presents a system of rational inference that helps us evaluate our models and make sounder judgments"},
	keywords = {Causal Reasoning,Legal},
	file = {/Users/alexwzk/Zotero/storage/IIZL7372/Lagnado - 2022 - Explaining the evidence how the mind investigates the world.pdf}
}

@article{liefgreen2023Drawing,
	title = {Drawing Conclusions: Representing and Evaluating Competing Explanations},
	author = {Liefgreen, Alice and Lagnado, David A.},
	year = {2023},
	month = may,
	journal = {Cognition},
	volume = {234},
	pages = {105382},
	abstract = {Despite the increase in studies investigating people's explanatory preferences in the domains of psychology and philosophy, little is known about their preferences in more applied domains, such as the criminal justice system. We show that when people evaluate competing legal accounts of the same evidence, their explanatory preferences are affected by whether they are required to draw causal models of the evidence. In addition, we identify `mechanism' as an explanatory feature that people value when evaluating explanations. Although previous research has shown that people can reason correctly about causality, ours is one of the first studies to show that generating and drawing causal models directly affects people's evaluations of explanations. Our findings have implications for the development of normative models of legal arguments, which have so far adopted a singularly `unified' approach, as well as the development of modelling tools to support people's reasoning and decision-making in applied domains. Finally, they add to the literature on the cognitive basis of evaluating competing explanations in new domains.},
	keywords = {Causal Reasoning},
	file = {/Users/alexwzk/Zotero/storage/ULPGCXWQ/Liefgreen and Lagnado - 2023 - Drawing conclusions Representing and evaluating competing explanations.pdf;/Users/alexwzk/Zotero/storage/VYU4L5BD/S0010027723000161.html}
}

@article{lopes2022Machine,
	title = {Machine learning partners in criminal networks},
	author = {Lopes, Diego D. and da Cunha, Bruno R. and Martins, Alvaro F. and Gon{\c c}alves, Sebasti{\'a}n and Lenzi, Ervin K. and Hanley, Quentin S. and Perc, Matja{\v z} and Ribeiro, Haroldo V.},
	year = {2022},
	month = sep,
	journal = {Sci. Rep.},
	volume = {12},
	number = {1},
	pages = {15746},
	abstract = {Recent research has shown that criminal networks have complex organizational structures, but whether this can be used to predict static and dynamic properties of criminal networks remains little explored. Here, by combining graph representation learning and machine learning methods, we show that structural properties of political corruption, police intelligence, and money laundering networks can be used to recover missing criminal partnerships, distinguish among different types of criminal and legal associations, as well as predict the total amount of money exchanged among criminal agents, all with outstanding accuracy. We also show that our approach can anticipate future criminal associations during the dynamic growth of corruption networks with significant accuracy. Thus, similar to evidence found at crime scenes, we conclude that structural patterns of criminal networks carry crucial information about illegal activities, which allows machine learning methods to predict missing information and even anticipate future criminal behavior.},
	keywords = {Complex networks,Nonlinear phenomena},
	file = {/Users/alexwzk/Zotero/storage/7VS27SZR/Lopes et al. - 2022 - Machine learning partners in criminal networks.pdf}
}

@article{luan2024Knowledge,
	title = {Knowledge Graph-Based Bayesian Network Risk Assessment Model for Hydrogen Accidents},
	author = {Luan, Tingting and Li, Hongru and Wang, Kai and Zhang, Xue and Li, Xiaoyun},
	year = {2024},
	month = sep,
	journal = {International Journal of Hydrogen Energy},
	volume = {81},
	pages = {927--941},
	abstract = {A Bayesian network risk assessment model for hydrogen accidents based on a knowledge graph is proposed. The study uses hydrogen accident report texts to form hydrogen accident knowledge texts by analyzing, processing, and extracting text fragments with transparent causal relationships. Then, the Bert-BilSTM-CRF algorithm is used to extract knowledge, and the results are stored in the Neo4j database to construct a knowledge map, obtain the risk factors of hydrogen accidents, and complete the structural modeling of the Bayesian network. The improved SAM method is used to aggregate expert opinions, calculate the prior and posterior probability, and realize the parameter learning of the Bayesian network. Based on a knowledge graph, this forms a Bayesian network risk assessment model for hydrogen accidents. This model can evaluate and warn against hydrogen accidents in a data-driven manner and promote knowledge acquisition, analysis, and decision-making on hydrogen energy storage and transportation risks.},
	keywords = {Bayesian Network,Decision Making},
	file = {/Users/alexwzk/Zotero/storage/WI32XY29/Luan et al. - 2024 - Knowledge graph-based Bayesian network risk assessment model for hydrogen accidents.pdf;/Users/alexwzk/Zotero/storage/R78HVUUX/S0360319924030246.html}
}

@inproceedings{mahmood2024Designing,
	title = {Designing Behavior-Aware AI to Improve the Human-AI Team Performance in AI-Assisted Decision Making},
	booktitle = {IJCAI},
	author = {Mahmood, Syed Hasan Amin and Lu, Zhuoran and Yin, Ming},
	year = {2024},
	month = aug,
	volume = {4},
	pages = {3106--3114},
	abstract = {Electronic proceedings of IJCAI 2024},
	keywords = {AI,Decision Making},
	file = {/Users/alexwzk/Zotero/storage/W76L8VVZ/Mahmood et al. - 2024 - Designing Behavior-Aware AI to Improve the Human-AI Team Performance in AI-Assisted Decision Making.pdf}
}

@article{mckay2020Predicting,
	title = {Predicting Risk in Criminal Procedure: Actuarial Tools, Algorithms, AI and Judicial Decision-Making},
	author = {McKay, Carolyn},
	year = {2020},
	month = jan,
	journal = {Current Issues in Criminal Justice},
	volume = {32},
	number = {1},
	pages = {22--39},
	abstract = {Risk assessments are conducted at a number of decision points in criminal procedure including in bail, sentencing and parole as well as in determining extended supervision and continuing detention orders of high-risk offenders. Such risk assessments have traditionally been the function of the human discretion and intuition of judicial officers, based on clinical assessments, framed by legislation and common-law principles, and encapsulating the concept of individualised justice. Yet, the progressive technologisation of criminal procedure is witnessing the incursion of statistical, data-driven evaluations of risk. Human judicial evaluative functions are increasingly complemented by a range of actuarial, algorithmic, machine learning and Artificial Intelligence (AI) tools that purport to provide accurate predictive capabilities and objective, consistent risk assessments. But ethical concerns have been raised globally regarding algorithms as proprietary products with in-built statistical bias as well as the diminution of judicial human evaluation in favour of the machine. This article focuses on risk assessment and what happens when decision-making is delegated to a predictive tool. Specifically, this article scrutinises the inscrutable proprietary nature of such risk tools and how that may render the calculation of the risk score opaque and unknowable to both the offender and the court.},
	keywords = {AI,Causal Reasoning,Criminology},
	file = {/Users/alexwzk/Zotero/storage/PPZQG9SP/McKay - 2020 - Predicting risk in criminal procedure actuarial tools, algorithms, AI and judicial decision-making.pdf}
}

@article{moore2025Concerning,
	title = {Concerning the Responsible Use of AI in the U.S. Criminal Justice System},
	author = {Moore, Cristopher and Gill, Catherine and Bliss, Nadya and Butler, Kevin and Forrest, Stephanie and Lopresti, Dan and Maher, Mary Lou and Mentis, Helena and Shekhar, Shashi and Stent, Amanda and Turk, Matthew},
	year = {2025},
	month = aug,
	journal = {Commun. ACM},
	abstract = {Seeking insight into AI decision-making processes to better address bias and improve accountability in AI systems.},
	keywords = {AI,Legal},
	file = {/Users/alexwzk/Zotero/storage/4U6BVPLP/Moore et al. - 2025 - Concerning the Responsible Use of AI in the U.S. Criminal Justice System.pdf}
}

@article{motie2024Financial,
	title = {Financial fraud detection using graph neural networks: A systematic review},
	author = {Motie, Soroor and Raahemi, Bijan},
	year = {2024},
	month = apr,
	journal = {Expert Systems with Applications},
	volume = {240},
	pages = {122156},
	abstract = {Financial fraud is a persistent problem in the finance industry that may have severe consequences for individuals, businesses, and economies. Graph Neural Networks (GNNs) are a class of deep learning models designed to operate on graph data structures that consist of nodes and edges connecting them. GNNs have emerged as a powerful tool for detecting fraudulent activities in complex financial systems because they can analyze the network structure of financial transactions, capturing patterns and anomalies that traditional rule-based and machine learning methods might miss. The objective of this systematic review is to provide a comprehensive overview of the current state-of-the-art technologies in using Graph Neural Networks (GNNs) for financial fraud detection, identify the gaps and limitations in the existing research, and suggest potential directions for future research. We searched five academic databases, including Web of Science, Scopus, IEEE Xplore, ACM, and science direct using specific keywords and search strings related to graph neural networks, financial areas, and anomaly detection to identify relevant publications, resulting in a total of 388 unique articles. We selected the relevant publications based on the inclusion, exclusion, and quality assessment criteria, and 33 articles were included in the review. In addition, forward snowballing was used to identify relevant papers that were not captured in the initial search. Data was extracted from the selected articles, then analyzed and summarized to identify current state, gaps, and trends in the literature. Our review presents a new taxonomy of GNNs applied in financial fraud detection and identifies potential research directions in this field. We find that GNNs applied to financial fraud detection have mostly been employed in a supervised or semi-supervised manner, with limited exploration of unsupervised approaches. In addition to financial areas, we explore the different types of graphs such as homogeneous, heterogenous, static, temporal, and dynamic graphs, and investigate the various learning mechanisms and anomaly types studied. We also note a lack of research on edge-level and graph-level anomaly detection commonly employed in financial domain.},
	keywords = {Anomaly detection,Financial fraud detection,GNNs,Graph neural networks,Graph representation learning},
	file = {/Users/alexwzk/Zotero/storage/67L93RRP/Motie and Raahemi - 2024 - Financial fraud detection using graph neural networks A systematic review.pdf;/Users/alexwzk/Zotero/storage/6B8WTYP8/S0957417423026581.html}
}

@article{nyberg2022BARD,
	title = {BARD: A Structured Technique for Group Elicitation of Bayesian Networks to Support Analytic Reasoning},
	author = {Nyberg, Erik P. and Nicholson, Ann E. and Korb, Kevin B. and Wybrow, Michael and Zukerman, Ingrid and Mascaro, Steven and Thakur, Shreshth and Oshni Alvandi, Abraham and Riley, Jeff and Pearson, Ross and Morris, Shane and Herrmann, Matthieu and Azad, A.K.M. and Bolger, Fergus and Hahn, Ulrike and Lagnado, David},
	year = {2022},
	month = jun,
	journal = {Risk Analysis},
	volume = {42},
	number = {6},
	pages = {1155--1178},
	abstract = {Abstract In many complex, real-world situations, problem solving and decision making require effective reasoning about causation and uncertainty. However, human reasoning in these cases is prone to confusion and error. Bayesian networks (BNs) are an artificial intelligence technology that models uncertain situations, supporting better probabilistic and causal reasoning and decision making. However, to date, BN methodologies and software require (but do not include) substantial upfront training, do not provide much guidance on either the model building process or on using the model for reasoning and reporting, and provide no support for building BNs collaboratively. Here, we contribute a detailed description and motivation for our new methodology and application, Bayesian ARgumentation via Delphi (BARD). BARD utilizes BNs and addresses these shortcomings by integrating (1)~short, high-quality e-courses, tips, and help on demand; (2)~a stepwise, iterative, and incremental BN construction process; (3)~report templates and an automated explanation tool; and (4)~a multiuser web-based software platform and Delphi-style social processes. The result is an end-to-end online platform, with associated online training, for groups without prior BN expertise to understand and analyze a problem, build a model of its underlying probabilistic causal structure, validate and reason with the causal model, and (optionally) use it to produce a written analytic report. Initial experiments demonstrate that, for suitable problems, BARD aids in reasoning and reporting. Comparing their effect sizes also suggests BARD's BN-building and collaboration combine beneficially and cumulatively.},
	keywords = {Analytic Reasoning,Bayesian Network,Criminology,Important},
	file = {/Users/alexwzk/Zotero/storage/3XYWVQT3/Nyberg et al. - 2022 - BARD A Structured Technique for Group Elicitation of Bayesian Networks to Support Analytic Reasonin.pdf}
}

@inproceedings{qiao2025Speak,
	title = {Speak Last and Step-by-Step: The Effect of Order and Response Mode on Evidence Evaluation},
	booktitle = {CogSci},
	author = {Qiao, Mengxuan Helen and Lagnado, David},
	year = {2025},
	abstract = {Previous research on order effects in legal decision-making has produced mixed results, possibly due to different response modes adopted in the tasks: End-of-Sequence (EoS) or Step-by-Step (SbS), which might reflect different cognitive models that fact-finders employ during evidence evaluation and integration. This paper investigates how response mode interacts with evidence order to influence judgments of the probability of guilt and verdict. In Study 1 (N = 159), no order effects were found in the EoS condition; but a recency effect emerged in the SbS condition. Study 2 (N = 95) revealed no order effect when the first set of evidence was judged SbS and the second set EoS. We also found that participants' probability of guilt judgments were generally consistent with Bayesian predictions when they responded SbS, but not when they responded EoS. We discuss potential explanations for these findings and their implications for legal decision-making.},
	keywords = {Criminology,Decision Making},
	file = {/Users/alexwzk/Zotero/storage/K9GANVY9/Qiao and Lagnado - 2025 - Speak Last and Step-by-Step The Effect of Order and Response Mode on Evidence Evaluation.pdf}
}

@article{rassin2018Reducing,
	title = {Reducing Tunnel Vision With a Pen-and-Paper Tool for the Weighting of Criminal Evidence},
	author = {Rassin, Eric},
	year = {2018},
	month = jun,
	journal = {Journal Invest. Psychology},
	volume = {15},
	number = {2},
	pages = {227--233},
	abstract = {In order to prevent tunnel vision, and ultimately miscarriages of justice, police, prosecutors, and judges must remain open to alternative scenarios in which the suspect is in fact innocent. However, it is not evident from the literature that people are sufficiently aware of how alternative scenarios should be employed in the decision-making process. In the present research, participants read a case vignette and formed an impression of the suspect's guilt. Some participants were made familiar with an alternative scenario. Others were not only presented with an alternative scenario but were also instructed to score (with pen and paper) the extent to which every piece of evidence fitted in the primary and the alternative scenario. Findings suggest that this pen-and-paper task helped to reduce tunnel vision.},
	keywords = {Criminology,Responsible},
	file = {/Users/alexwzk/Zotero/storage/ALYY46HB/Rassin - 2018 - Reducing tunnel vision with a pen‐and‐paper tool for the weighting of criminal evidence.pdf}
}

@article{raval2025Criminal,
	title = {Criminal Emotion Detection Framework Using Convolutional Neural Network for Public Safety},
	author = {Raval, Jay and Jadav, Nilesh Kumar and Tanwar, Sudeep and Pau, Giovanni and Alqahtani, Fayez and Tolba, Amr},
	year = {2025},
	month = may,
	journal = {Sci. Rep.},
	volume = {15},
	number = {1},
	pages = {15279},
	abstract = {In the era of rapid societal modernization, the issue of crime stands as an intrinsic facet, demanding our attention and consideration. As our communities evolve and adopt technological advancements, the dynamic landscape of criminal activities becomes an essential aspect that requires careful examination and proactive approaches for public safety application. In this paper, we proposed a collaborative approach to detect crime patterns and criminal emotions with the aim of enhancing judiciary decision-making. For the same, we utilized two standard datasets - a crime dataset comprised of different features of crime. Further, the emotion dataset has 135 classes of emotion that help the AI model to efficiently find criminal emotions. We adopted a convolutional neural network (CNN) to get first trained on crime datasets to bifurcate crime and non-crime images. Once the crime is detected, criminal faces are extracted using the region of interest and stored in a directory. Different CNN architectures, such as LeNet-5, VGGNet, RestNet-50, and basic CNN, are used to detect different emotions of the face. The trained CNN models are used to detect criminal emotion and enhance judiciary decision-making. The proposed framework is evaluated with different evaluation metrics, such as training accuracy, loss, optimizer performance, precision-recall curve, model complexity, training time, and inference time. In crime detection, the CNN model achieves a remarkable accuracy of 92.45\% and in criminal emotion detection, LeNet-5 outperforms other CNN architectures by offering an accuracy of 98.6\%.},
	keywords = {AI,Computer science,Dataset,Digital Forensics,Information technology},
	file = {/Users/alexwzk/Zotero/storage/X5WXETXJ/Raval et al. - 2025 - Criminal emotion detection framework using convolutional neural network for public safety.pdf}
}

@misc{reynisson2024GraphGuard,
	title = {GraphGuard: Contrastive Self-Supervised Learning for Credit-Card Fraud Detection in Multi-Relational Dynamic Graphs},
	author = {Reynisson, Krist{\'o}fer and Schreyer, Marco and Borth, Damian},
	year = {2024},
	month = jul,
	number = {arXiv:2407.12440},
	eprint = {2407.12440},
	publisher = {arXiv},
	abstract = {Credit card fraud has significant implications at both an individual and societal level, making effective prevention essential. Current methods rely heavily on feature engineering and labeled information, both of which have significant limitations. In this work, we present GraphGuard, a novel contrastive self-supervised graph-based framework for detecting fraudulent credit card transactions. We conduct experiments on a real-world dataset and a synthetic dataset. Our results provide a promising initial direction for exploring the effectiveness of graph-based self-supervised approaches for credit card fraud detection.},
	archiveprefix = {arXiv},
	keywords = {Computer Science - Machine Learning},
	file = {/Users/alexwzk/Zotero/storage/CF6KMD7L/Reynisson et al. - 2024 - GraphGuard Contrastive Self-Supervised Learning for Credit-Card Fraud Detection in Multi-Relational.pdf;/Users/alexwzk/Zotero/storage/V4YPYP3V/2407.html}
}

@article{richardson2019Dirty,
	title = {Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice},
	author = {Richardson, Rashida and Schultz, Jason M and Crawford, Kate},
	year = {2019},
	journal = {NYUL Rev. Online},
	volume = {94},
	pages = {15},
	abstract = {Law enforcement agencies are increasingly using predictive policing systems to forecast criminal activity and allocate police resources. Yet in numerous jurisdictions, these systems are built on data produced during documented periods of flawed, racially biased, and sometimes unlawful practices and policies (``dirty policing''). These policing practices and policies shape the environment and the methodology by which data is created, which raises the risk of creating inaccurate, skewed, or systemically biased data (``dirty data''). If predictive policing systems are informed by such data, they cannot escape the legacies of the unlawful or biased policing practices that they are built on. Nor do current claims by predictive policing vendors provide sufficient assurances that their systems adequately mitigate or segregate this data. In our research, we analyze thirteen jurisdictions that have used or developed predictive policing tools while under government commission investigations or federal court monitored settlements, consent decrees, or memoranda of agreement stemming from corrupt, racially biased, or otherwise illegal policing practices. In particular, we examine the link between unlawful and biased police practices and the data available to train or implement these systems. We highlight three case studies: (1) Chicago, an example of where dirty data was ingested directly into the city's predictive system; (2) New Orleans, an example where the extensive evidence of dirty policing practices and recent litigation suggests an extremely high risk that dirty data was or could be used in predictive policing; and (3) Maricopa County, where despite extensive evidence of dirty policing practices, a lack of public transparency about the details of various predictive policing systems restricts a proper assessment of the risks. The implications of these findings have widespread ramifications for predictive policing writ large. Deploying predictive policing systems in jurisdictions with extensive histories of unlawful police practices presents elevated risks that dirty data will lead to flawed or unlawful predictions, which in turn risk perpetuating additional harm via feedback loops throughout the criminal justice system. The use of predictive policing must be treated with high levels of caution and mechanisms for the public to know, assess, and reject such systems are imperative.},
	keywords = {Dataset,Important,Legal},
	file = {/Users/alexwzk/Zotero/storage/89A3MLZI/Richardson et al. - DIRTY DATA, BAD PREDICTIONS HOW CIVIL RIGHTS VIOLATIONS IMPACT POLICE DATA, PREDICTIVE POLICING SYS.pdf}
}

@misc{schlichtkrull2017Modeling,
	title = {Modeling Relational Data with Graph Convolutional Networks},
	author = {Schlichtkrull, Michael and Kipf, Thomas N. and Bloem, Peter and van den Berg, Rianne and Titov, Ivan and Welling, Max},
	year = {2017},
	month = oct,
	number = {arXiv:1703.06103},
	eprint = {1703.06103},
	publisher = {arXiv},
	abstract = {Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to deal with the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved by enriching them with an encoder model to accumulate evidence over multiple inference steps in the relational graph, demonstrating a large improvement of 29.8\% on FB15k-237 over a decoder-only baseline.},
	archiveprefix = {arXiv},
	keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Machine Learning,Statistics - Machine Learning},
	file = {/Users/alexwzk/Zotero/storage/DA6B56PV/Schlichtkrull et al. - 2017 - Modeling Relational Data with Graph Convolutional Networks.pdf;/Users/alexwzk/Zotero/storage/6PYRZI3U/1703.html}
}

@article{shengelia2021Are,
	title = {Are Jurors Intuitive Statisticians? Bayesian Causal Reasoning in Legal Contexts},
	author = {Shengelia, Tamara and Lagnado, David},
	year = {2021},
	month = feb,
	journal = {Front. Psychol.},
	volume = {11},
	abstract = {In criminal trials, evidence often involves a degree of uncertainty and decision-making includes moving from the initial presumption of innocence to inference about guilt based on that evidence. The jurors' ability to combine evidence and make accurate intuitive probabilistic judgments underpins this process. Previous research has shown that errors in probabilistic reasoning can be explained by a misalignment of the evidence presented with the intuitive causal models that people construct. This has been explored in abstract and context-free situations. However, less is known about how people interpret evidence in context-rich situations such as legal cases. The present study examined participants' intuitive probabilistic reasoning in legal contexts and assessed how people's causal models underlie the process of belief updating in the light of new evidence. The study assessed whether participants update beliefs in line with Bayesian norms and if errors in belief updating can be explained by the causal structures underpinning the evidence integration process. The study was based on a recent case in England where a couple was accused of intentionally harming their baby but were eventually exonerated because the child's symptoms were found to be caused by a rare blood disorder. Participants were presented with a range of evidence, one piece at a time, including physical evidence and reports from experts. Participants made probability judgments about the abuse and disorder as causes of the child's symptoms. Subjective probability judgments were compared against Bayesian norms. The causal models constructed by participants were also elicited. Results showed that overall participants revised their beliefs appropriately in the right direction based on evidence. However, this revision was done without exact Bayesian computation and errors were observed in estimating the weight of evidence. Errors in probabilistic judgments were partly accounted for, by differences in the causal models representing the evidence. Our findings suggest that understanding causal models that guide people's judgments may help shed light on errors made in evidence integration and potentially identify ways to address accuracy in judgment.},
	keywords = {Bayesian Network,Causal Reasoning,Legal},
	file = {/Users/alexwzk/Zotero/storage/IUTGPR7X/Shengelia and Lagnado - 2021 - Are Jurors Intuitive Statisticians Bayesian Causal Reasoning in Legal Contexts.pdf}
}

@article{solanke2022Digital,
	title = {Digital Forensics AI: Evaluating, Standardizing and Optimizing Digital Evidence Mining Techniques},
	author = {Solanke, Abiodun A. and Biasiotti, Maria Angela},
	year = {2022},
	month = sep,
	journal = {K{\"u}nstl Intell},
	volume = {36},
	number = {2},
	pages = {143--161},
	abstract = {The impact of AI on numerous sectors of our society and its successes over the years indicate that it can assist in resolving a variety of complex digital forensics investigative problems. Forensics analysis can make use of machine learning models' pattern detection and recognition capabilities to uncover hidden evidence in digital artifacts that would have been missed if conducted manually. Numerous works have proposed ways for applying AI to digital forensics; nevertheless, scepticism regarding the opacity of AI has impeded the domain's adequate formalization and standardization. We present three critical instruments necessary for the development of sound machine-driven digital forensics methodologies in this paper. We cover various methods for evaluating, standardizing, and optimizing techniques applicable to artificial intelligence models used in digital forensics. Additionally, we describe several applications of these instruments in digital forensics, emphasizing their strengths and weaknesses that may be critical to the methods' admissibility in a judicial process.},
	keywords = {AI,Digital Forensics},
	file = {/Users/alexwzk/Zotero/storage/29ZXAZPP/Solanke and Biasiotti - 2022 - Digital Forensics AI Evaluating, Standardizing and Optimizing Digital Evidence Mining Techniques.pdf}
}

@article{sunde2019Cognitive,
	title = {Cognitive and Human Factors in Digital Forensics: Problems, Challenges, and the Way Forward},
	author = {Sunde, Nina and Dror, Itiel E.},
	year = {2019},
	month = jun,
	journal = {Digital Investigation},
	volume = {29},
	pages = {101--108},
	abstract = {Digital forensics is an important and growing forensic domain. Research on miscarriages of justice and misleading evidence, as well as various inquires in the UK and the US, have highlighted human error as an issue within forensic science. This has led to increased attention to the sources of cognitive bias and potential countermeasures within many forensic disciplines. However, the area of digital forensics has yet to pay sufficient attention to this issue. The main goal of this article is to contribute to a more scientifically sound digital forensics domain by addressing the issues of cognitive bias as a source of error. In this paper we present an analysis of seven sources of cognitive and human error specifically within the digital forensics process, and discuss relevant countermeasures. We conclude that although some cognitive and bias issues are very similar across forensic domains, others are different and dependent on the specific characteristic of the domain in question, such as digital forensics. There is a need for new directions in research with regard to cognitive and human factors in digital forensics.},
	keywords = {Causal Reasoning,Digital Forensics},
	file = {/Users/alexwzk/Zotero/storage/WYYHQQVA/Sunde and Dror - 2019 - Cognitive and human factors in digital forensics Problems, challenges, and the way forward.pdf}
}

@article{syedahmedali2022Cloud,
	title = {Cloud Forensics Framework for Law Enforcement Agencies},
	author = {Syed Ahmed Ali, Shahzad Memon},
	year = {2022},
	journal = {Journal of Southwest Jiaotong University},
	volume = {57},
	number = {2},
	abstract = {Internet-based cloud technology is a network of remote data centers often placed beyond the country's legal frontiers worldwide. Contrary to the benefits of cloud computing, it is also a target of cybercriminals who may affect its resources on a larger scale by a single exploit. For protecting the cloud resources and increasing the confidence of cloud users, it is necessary to make one accountable for disrupting its services based on relevant evidence that proves someone's guilt in a court of law. In the literature, various frameworks have been presented for evidence collection against the attack on the cloud service for Cloud Service providers (CSP), but there is no framework for LEAs. Unfortunately, the evidence of a security breach in the cloud resides under the control of CSP, which is the sole custodian of cloud resources. However, the CSP does not fully cooperate with the investigators due to various legal, technical, and operational reasons. Hence the entire prosecution is dependent on the provision of evidence by the CSP, which is a great challenge for law enforcement around the world. The study's objective is to design a framework that mitigates the dependency of CSP by collecting the evidence of a security incident outside the cloud by colluding the Internet Service Providers (ISPs) and law Enforcement for a particular cloud service. The framework integrates the components that can detect the attack on a cloud service earlier at ISP and store the logs of the incident in a forensic server which can be used for forensics purposes as and when required.},
	file = {/Users/alexwzk/Zotero/storage/WC3PAZRI/Syed Ahmed Ali - 2022 - CLOUD FORENSICS FRAMEWORK FOR LAW ENFORCEMENT AGENCIES.pdf}
}

@article{tatlidil2025Comparison,
	title = {A Comparison of Methods to Elicit Causal Structure},
	author = {Tatlidil, Semir and Sloman, Steven A. and Basu, Semanti and Tran, Tiffany and Saxena, Serena and Kim, Moon Hwan and Bahar, Iris},
	year = {2025},
	month = may,
	journal = {Front. Cognit.},
	volume = {4},
	pages = {1544387},
	abstract = {We compare two methods to elicit graphs from people that represent the causal structure of common artifacts. One method asks participants to focus narrowly on local causal relations and is based on the ``make-a-difference'' view of causality, specifically on an interventional theory of causality and so we call it ``Intervention.'' It asks subjects to answer a series of counterfactual questions. The second method draws directly from the graphical aspect of Causal Bayesian Networks and allows people to consider causal structure at a more global level. It involves drawing causal graphs using an online interface called ``Loopy.'' This method does not depend on a definition of causal relatedness. We use signal detection theory to analyze the likelihoods of people generating correct and incorrect causal relations (hit rates and false alarm rates, respectively) using each method. The results show that the intervention method leads people to generate more accurate causal models.},
	keywords = {Causal Reasoning},
	file = {/Users/alexwzk/Zotero/storage/9HNPDZNX/Tatlidil et al. - 2025 - A comparison of methods to elicit causal structure.pdf}
}

@article{taylor2023Justice,
	title = {Justice by Algorithm: The Limits of AI in Criminal Sentencing},
	author = {Taylor, Isaac},
	year = {2023},
	month = sep,
	journal = {Criminal Justice Ethics},
	volume = {42},
	number = {3},
	pages = {193--213},
	abstract = {Criminal justice systems have traditionally relied heavily on human decision-making, but new technologies are increasingly supplementing the human role in this sector. This paper considers what general limits need to be placed on the use of algorithms in sentencing decisions. It argues that, even once we can build algorithms that equal human decision-making capacities, strict constraints need to be placed on how they are designed and developed. The act of condemnation is a valuable element of criminal sentencing, and using algorithms in sentencing -- even in an advisory role -- threatens to undermine this value. The paper argues that a principle of ``meaningful public control'' should be met in all sentencing decisions if they are to retain their condemnatory status. This principle requires that agents who have standing to act on behalf of the wider political community retain moral responsibility for all sentencing decisions. While this principle does not rule out the use of algorithms, it does require limits on how they are constructed.},
	keywords = {AI,Causal Reasoning,Legal},
	file = {/Users/alexwzk/Zotero/storage/JQBXVSEN/Taylor - 2023 - Justice by Algorithm The Limits of AI in Criminal Sentencing.pdf}
}

@inproceedings{vanleeuwen2023Evaluating,
	title = {Evaluating Methods for Setting a Prior Probability of Guilt},
	booktitle = {JURIX},
	author = {Van Leeuwen, Ludi and Verheij, Bart and Verbrugge, Rineke and Renooij, Silja},
	editor = {Sileno, Giovanni and Spanakis, Jerry and Van Dijck, Gijs},
	year = {2023},
	month = dec,
	abstract = {One way of reasoning with uncertainties in the context of law is to use probabilities. However, methods for reasoning about the probability of guilt in a court case requires us to specify a prior probability of guilt, which is the probability of guilt before any evidence is known. There is no accepted approach for specifying the prior probability of guilt but multiple solutions have been proposed. In this paper, we consider three approaches: a prior that is based on the population, a prior based on the number of agents that have similar opportunity as the suspect and a prior that represents a legal norm. For comparing and evaluating the approaches, we use an agent-based model as a ground truth in which all probabilities are known. With the data generated in the ground truth model, we investigate how the choice of prior influences the posterior probability of guilt for both guilty and innocent agents. Using a decision threshold, we can determine the effect of the three approaches on the rates of correct and incorrect convictions and acquittals. We find that the opportunity prior results in higher rates of both correct convictions and false convictions and requires more assumptions and access to data and knowledge than the legal prior and population prior.},
	keywords = {Bayesian Network,Important},
	file = {/Users/alexwzk/Zotero/storage/BHYQUH8Q/Van Leeuwen et al. - 2023 - Evaluating Methods for Setting a Prior Probability of Guilt.pdf}
}

@inproceedings{vanleeuwen2024Building,
	title = {Building a Stronger Case: Combining Evidence and Law in Scenario-Based Bayesian Networks},
	booktitle = {HHAI},
	author = {Van Leeuwen, Ludi and Verbrugge, Rineke and Verheij, Bart and Renooij, Silja},
	editor = {Lorig, Fabian and Tucker, Jason and Dahlgren Lindstr{\"o}m, Adam and Dignum, Frank and Murukannaiah, Pradeep and Theodorou, Andreas and Yolum, P{\i}nar},
	year = {2024},
	month = jun,
	abstract = {Existing approaches to modelling legal cases in Bayesian networks focus either on correctly representing an empirical probabilistic model of evidence traces, or on modeling alternative scenarios that can explain what happened in a case. However, neither approach legally interprets, or qualifies, aspects of a scenario as a normative legal fact. Hence, the fact that a Bayesian network representing a scenario assigns a high posterior probability to a certain victim having been killed by a certain suspect, does not imply that that suspect is guilty of murder in the legal sense, because the events in the scenario cannot be qualified as legal facts. This paper proposes an architecture for concrete legal fact idioms that qualify events in a narrative Bayesian network. This bridges the gap between the real world and the normative legal world through so-called counts-as rules. By modeling the legal facts explicitly in the Bayesian network, we can show whether a narrative completes one or more legal fact idioms. This is demonstrated using a case study. The proposed architecture may help judges and lawyers decide on which narratives they should investigate further and which narratives are stronger than others with regard to both the evidence and the legal facts.},
	keywords = {Bayesian Network,Legal},
	file = {/Users/alexwzk/Zotero/storage/BDMHDJYK/Van Leeuwen et al. - 2024 - Building a Stronger Case Combining Evidence and Law in Scenario-Based Bayesian Networks.pdf}
}

@article{vink2023Collection,
	title = {A Collection of Idioms for Modeling Activity Level Evaluations in Forensic Science},
	author = {Vink, M. and Sjerps, M. J.},
	year = {2023},
	month = jan,
	journal = {Forensic Science International: Synergy},
	volume = {6},
	pages = {100331},
	abstract = {This paper presents a collection of idioms that is useful for modeling activity level evaluations in forensic science using Bayesian networks. The idioms are categorized into five groups: cause-consequence idioms, narrative idioms, synthesis idioms, hypothesis-conditioning idioms, and evidence-conditioning idioms. Each category represents a specific modeling objective. Furthermore, we support the use of an idiom-based approach and emphasize the relevance of our collection by combining several of the presented idioms to create a more comprehensive template model. This model can be used in cases involving transfer evidence and disputes over the actor and/or activity. Additionally, we cite literature that employs idioms in template models or case-specific models, providing the reader with examples of their use in forensic casework.},
	keywords = {Bayesian Network,General Forensics},
	file = {/Users/alexwzk/Zotero/storage/27D8LJZ7/Vink and Sjerps - 2023 - A Collection of Idioms for Modeling Activity Level Evaluations in Forensic Science.pdf}
}

@misc{weber2019AntiMoney,
	title = {Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics},
	author = {Weber, Mark and Domeniconi, Giacomo and Chen, Jie and Weidele, Daniel Karl I. and Bellei, Claudio and Robinson, Tom and Leiserson, Charles E.},
	year = {2019},
	month = jul,
	number = {arXiv:1908.02591},
	eprint = {1908.02591},
	publisher = {arXiv},
	abstract = {Anti-money laundering (AML) regulations play a critical role in safeguarding financial systems, but bear high costs for institutions and drive financial exclusion for those on the socioeconomic and international margins. The advent of cryptocurrency has introduced an intriguing paradox: pseudonymity allows criminals to hide in plain sight, but open data gives more power to investigators and enables the crowdsourcing of forensic analysis. Meanwhile advances in learning algorithms show great promise for the AML toolkit. In this workshop tutorial, we motivate the opportunity to reconcile the cause of safety with that of financial inclusion. We contribute the Elliptic Data Set, a time series graph of over 200K Bitcoin transactions (nodes), 234K directed payment flows (edges), and 166 node features, including ones based on non-public data; to our knowledge, this is the largest labelled transaction data set publicly available in any cryptocurrency. We share results from a binary classification task predicting illicit transactions using variations of Logistic Regression (LR), Random Forest (RF), Multilayer Perceptrons (MLP), and Graph Convolutional Networks (GCN), with GCN being of special interest as an emergent new method for capturing relational information. The results show the superiority of Random Forest (RF), but also invite algorithmic work to combine the respective powers of RF and graph methods. Lastly, we consider visualization for analysis and explainability, which is difficult given the size and dynamism of real-world transaction graphs, and we offer a simple prototype capable of navigating the graph and observing model performance on illicit activity over time. With this tutorial and data set, we hope to a) invite feedback in support of our ongoing inquiry, and b) inspire others to work on this societally important challenge.},
	archiveprefix = {arXiv},
	keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Quantitative Finance - General Finance},
	file = {/Users/alexwzk/Zotero/storage/7I8JRGCT/Weber et al. - 2019 - Anti-Money Laundering in Bitcoin Experimenting with Graph Convolutional Networks for Financial Fore.pdf;/Users/alexwzk/Zotero/storage/CRVECHLQ/1908.html}
}

@article{wojciechowski2018There,
	title = {Is There a Conjunction Fallacy in Legal Probabilistic Decision Making?},
	author = {Wojciechowski, B. W. and Pothos, E. M.},
	year = {2018},
	journal = {Frontiers in Psychology},
	volume = {9},
	number = {APR},
	abstract = {Classical probability theory (CPT) has represented the rational standard for decision making in human cognition. Even though CPT has provided many descriptively excellent decision models, there have also been some empirical results persistently problematic for CPT accounts. The tension between the normative prescription of CPT and human behavior is particularly acute in cases where we have higher expectations for rational decisions. One such case concerns legal decision making from legal experts, such as attorneys and prosecutors and, more so, judges. In the present research we explore one of the most influential CPT decision fallacies, the conjunction fallacy (CF), in a legal decision making task, involving assessing evidence that the same suspect had committed two separate crimes. The information for the two crimes was presented consecutively. Each participant was asked to provide individual ratings for the two crimes in some cases and conjunctive probability rating for both crimes in other cases, after all information had been presented. Overall, 360 probability ratings for guilt were collected from 120 participants, comprised of 40 judges, 40 attorneys and prosecutors, and 40 individuals without legal education. Our results provide evidence for a double conjunction fallacy (in this case, a higher probability of committing both crimes than the probability of committing either crime individually), in the group of individuals without legal education. These results are discussed in terms of their applied implications and in relation to a recent framework for understanding such results, quantum probability theory (QPT).},
	keywords = {Analytic Reasoning,Legal},
	file = {/Users/alexwzk/Zotero/storage/BV3L4Q57/Wojciechowski and Pothos - 2018 - Is there a conjunction fallacy in legal probabilistic decision making.pdf;/Users/alexwzk/Zotero/storage/RT57IX6U/fpsyg.2018.html}
}

@article{xiao2023MINT,
	title = {MINT: Detecting Fraudulent Behaviors from Time-Series Relational Data},
	author = {Xiao, Fei and Wu, Yuncheng and Zhang, Meihui and Chen, Gang and Ooi, Beng Chin},
	year = {2023},
	month = aug,
	journal = {Proc. VLDB Endow.},
	volume = {16},
	number = {12},
	pages = {3610--3623},
	abstract = {The e-commerce platforms, such as Shopee, have accumulated a huge volume of time-series relational data, which contains useful information on differentiating fraud users from benign users. Existing fraud behavior detection approaches typically model the time-series data with a vanilla Recurrent Neural Network (RNN) or combine the whole sequence as a single intention without considering the temporal behavioral patterns, row-level interactions, and different view intentions. In this paper, we present MINT, a Multiview row-INteractive Time-aware framework to detect fraudulent behaviors from time-series structured data. The key idea of MINT is to build a time-aware behavior graph for each user's time-series relational data with each row represented as an action node. We utilize the user's temporal information to construct three different graph convolutional matrices for hierarchically learning the user's intentions from different views, that is, short-term, medium-term, and long-term intentions. To capture more meaningful row-level interactions and alleviate the over-smoothing issue in a vanilla time-aware behavior graph, we propose a novel gated neighbor interaction mechanism to calibrate the aggregated information by each action node. Since the receptive fields of the three graph convolutional layers are designed to grow nearly exponentially, our MINT requires many fewer layers than traditional deep graph neural networks (GNNs) to capture multi-hop neighboring information, and avoids recurrent feedforward propagation, thus leading to higher training efficiency and scalability. Our extensive experiments on the large-scale e-commerce datasets from Shopee with up to 4.6 billion records and a public dataset from Amazon show that MINT achieves superior performance over 10 state-of-the-art models and provides better interpretability and scalability.},
	file = {/Users/alexwzk/Zotero/storage/2N52KCA6/Xiao et al. - 2023 - MINT Detecting Fraudulent Behaviors from Time-Series Relational Data.pdf}
}

@article{xu2022Human,
	title = {Human Judges in the Era of Artificial Intelligence: Challenges and Opportunities},
	author = {Xu, Zichun},
	year = {2022},
	month = dec,
	journal = {Applied Artificial Intelligence},
	volume = {36},
	number = {1},
	pages = {2013652},
	abstract = {In recent years, artificial intelligence technology has been widely used in the field of justice. Compared with human judges, judicial artificial intelligence is more efficient, experience and objective. But artificial intelligence has its limits. Artificial intelligence is still essentially machine intelligence based on big data, algorithms and computing power, not organic intelligence. Subject to the difference between judicial artificial intelligence and human judges in knowledge structure, application scenario and potential ability, judicial artificial intelligence can not completely replace human judges. Therefore, it is important to make it clear that judicial artificial intelligence is only a helper of human judges, not a stand-in. Firstly, it should give full play to the role of judicial artificial intelligence in dealing with simple cases and transactional work. Secondly, the roles and functions of judges should be actively transformed to make them more professional, rational and warm.},
	keywords = {AI,Causal Reasoning,Legal},
	file = {/Users/alexwzk/Zotero/storage/EAV522ZN/Xu - 2022 - Human Judges in the Era of Artificial Intelligence Challenges and Opportunities.pdf}
}

@inproceedings{zhang2020Effect,
	title = {Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making},
	booktitle = {FAT*},
	author = {Zhang, Yunfeng and Liao, Q. Vera and Bellamy, Rachel K. E.},
	year = {2020},
	month = jan,
	pages = {295--305},
	abstract = {Today, AI is being increasingly used to help human experts make decisions in high-stakes scenarios. In these scenarios, full automation is often undesirable, not only due to the significance of the outcome, but also because human experts can draw on their domain knowledge complementary to the model's to ensure task success. We refer to these scenarios as AI-assisted decision making, where the individual strengths of the human and the AI come together to optimize the joint decision outcome. A key to their success is to appropriately calibrate human trust in the AI on a case-by-case basis; knowing when to trust or distrust the AI allows the human expert to appropriately apply their knowledge, improving decision outcomes in cases where the model is likely to perform poorly. This research conducts a case study of AI-assisted decision making in which humans and AI have comparable performance alone, and explores whether features that reveal case-specific model information can calibrate trust and improve the joint performance of the human and AI. Specifically, we study the effect of showing confidence score and local explanation for a particular prediction. Through two human experiments, we show that confidence score can help calibrate people's trust in an AI model, but trust calibration alone is not sufficient to improve AI-assisted decision making, which may also depend on whether the human can bring in enough unique knowledge to complement the AI's errors. We also highlight the problems in using local explanation for AI-assisted decision making scenarios and invite the research community to explore new approaches to explainability for calibrating human trust in AI.},
	keywords = {AI,Decision Making,Responsible},
	file = {/Users/alexwzk/Zotero/storage/523X9C96/Zhang et al. - 2020 - Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision makin.pdf}
}
